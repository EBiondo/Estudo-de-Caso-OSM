{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos para geração dos arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# código que itera o arquivo OSM grava os valores correspondentes às chaves em um arquivo csv\n",
    "\n",
    "osm_file = 'map' # variável que representa o arquivo a ser aberto\n",
    "\n",
    "d = [] # lista dos elementos das tags nodes\n",
    "\n",
    "def shape_element(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    element = tree.getroot()\n",
    "       \n",
    "    for el in element.iter():\n",
    "        if el.tag == \"node\":\n",
    "            nodes = {}\n",
    "            for item in el.attrib:\n",
    "                nodes_list = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "                if item in nodes_list:\n",
    "                    nodes[item] = el.get(item)\n",
    "                    #pprint.pprint(nodes)\n",
    "            d.append(nodes)\n",
    "            nodes = {}\n",
    "            \n",
    "            with open('nodes.csv', 'w', encoding='utf-8') as csv_file:\n",
    "                nodes_list = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = nodes_list)\n",
    "                writer.writeheader()\n",
    "                for dic in d:\n",
    "                    data = {key: value for key, value in dic.items() if key in nodes_list}\n",
    "                    writer.writerow(data)\n",
    "                    \n",
    "shape_element(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "osm_file = 'map'\n",
    "\n",
    "e = [] # lista dos elementos das tags ways\n",
    "\n",
    "def shape_element(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    element = tree.getroot()\n",
    "              \n",
    "    \n",
    "    for el in element.iter():\n",
    "        if el.tag == 'way':\n",
    "            ways = {}\n",
    "            for item in el.attrib:\n",
    "                ways_list = [\"id\", \"user\",\"uid\", \"version\", \"changeset\", \"timestamp\"]\n",
    "                if item in ways_list:\n",
    "                    ways[item] = el.get(item)\n",
    "            e.append(ways)\n",
    "            ways = {}\n",
    "            \n",
    "            with open('ways.csv', 'w', encoding='utf-8') as csv_file:\n",
    "                ways_list = [\"id\", \"user\",\"uid\", \"version\", \"changeset\", \"timestamp\"]\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = ways_list)\n",
    "                writer.writeheader()\n",
    "                for dic in e:\n",
    "                    data = {key: value for key, value in dic.items() if key in ways_list}\n",
    "                    writer.writerow(data)\n",
    "                     \n",
    "shape_element(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "osm_file = 'map'\n",
    "\n",
    "g = [] # lista dos elementos ways_tags\n",
    "\n",
    "def shape_element(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    element = tree.getroot()\n",
    "    \n",
    "    for el in element.iter():\n",
    "        if el.tag == 'way':\n",
    "            ways_tags = {}\n",
    "            for i in el.iter('tag'):\n",
    "                ways_tags['key'] = i.get('k')\n",
    "                ways_tags['value'] = i.get('v')\n",
    "                ways_tags['type'] = el.tag\n",
    "                g.append(nodes_tags)\n",
    "                nodes_tags = {}\n",
    "            \n",
    "    \n",
    "            with open('ways_tags.csv', 'w', encoding='utf-8') as csv_file:\n",
    "                fieldnames = ['key', 'value', 'type']\n",
    "                writer = csv.DictWriter(csv_file, fieldnames = fieldnames)\n",
    "                writer.writeheader()\n",
    "                for dic in g:\n",
    "                    data = {key: value for key, value in dic.items() if key in fieldnames}\n",
    "                    writer.writerow(data)\n",
    "\n",
    "shape_element(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "osm_file = 'map'\n",
    "\n",
    "h = [] # lista dos elementos ways_tags\n",
    "\n",
    "def shape_element(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    element = tree.getroot()\n",
    "    \n",
    "    for el in element.iter():\n",
    "        if el.tag == 'way':\n",
    "            ways_nodes = {}\n",
    "            for i in el.iter('tag'):\n",
    "                if i.tag == 'nd':\n",
    "                    ways_nodes['position'] = i.get('ref')\n",
    "                    h.append(ways_nodes)\n",
    "                    ways_nodes = {}\n",
    "            \n",
    "            with open('ways_nodes.csv', 'w', encoding='utf-8') as csv_file:\n",
    "                fieldnames = ['position']\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                for dic in h:\n",
    "                    data = {key: value for key, value in dic.items() if key in fieldnames}\n",
    "                    writer.writerow(data)  \n",
    "                    \n",
    "shape_element(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('data_wrangling_sqlite.db') #nome do banco de dados\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "with open('nodes_tags.csv', 'r', encoding='utf-8') as file:\n",
    "    dr = csv.DictReader(file) # nome do arquivo csv\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "    # i['nome da coluna']\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags VALUES (?,?,?,?);\", to_db)# ? = número de colunas\n",
    "\n",
    "con.commit()\n",
    "\n",
    "cur.close()\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('data_wrangling_sqlite.db', timeout=60000, isolation_level=None) #nome do banco de dados\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "with open('nodes.csv', 'r', encoding='utf-8') as file:\n",
    "    dr = csv.DictReader(file) # nome do arquivo csv\n",
    "    to_db = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    # i['nome da coluna']\n",
    "\n",
    "con.execute(\"PRAGMA busy_timeout = 60000\")   # 60 s\n",
    "\n",
    "cur.executemany('INSERT INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?,?,?);', to_db)# ? = número de colunas\n",
    "\n",
    "con.commit()\n",
    "\n",
    "cur.close()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('data_wrangling_sqlite.db') #nome do banco de dados\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "with open('ways.csv', 'r', encoding='utf-8') as file:\n",
    "    dr = csv.DictReader(file) # nome do arquivo csv\n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    # i['nome da coluna']\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways VALUES (?,?,?,?,?,?);\", to_db)# ? = número de colunas\n",
    "\n",
    "con.commit()\n",
    "\n",
    "cur.close()\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "osm_file = 'map'\n",
    "\n",
    "f = [] # lista dos elementos nodes_tags\n",
    "\n",
    "def shape_element(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    element = tree.getroot()\n",
    "    \n",
    "    nodes_tags = {}\n",
    "    for el in element.iter():\n",
    "        if el.tag == \"node\":\n",
    "            \n",
    "            for e in el.iter('tag'):\n",
    "                nodes_tags['id'] = el.get('id')\n",
    "                nodes_tags['key'] = e.get('k')\n",
    "                nodes_tags['value'] = e.get('v')\n",
    "                nodes_tags['type'] = el.tag\n",
    "                f.append(nodes_tags)\n",
    "                nodes_tags = {}\n",
    "                \n",
    "            with open('nodes_tags.csv', 'w', encoding='utf-8') as csv_file:\n",
    "                fieldnames = ['id', 'key', 'value', 'type']\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                for dic in f:\n",
    "                    data = {key: value for key, value in dic.items() if key in fieldnames}\n",
    "                    writer.writerow(data)            \n",
    "shape_element(osm_file)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('data_wrangling_sqlite.db') #nome do banco de dados\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "with open('ways_nodes.csv', 'r', encoding='utf-8') as file:\n",
    "    dr = csv.DictReader(file) # nome do arquivo csv\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "    # i['nome da coluna']\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes VALUES (?,?,?);\", to_db)# ? = número de colunas\n",
    "\n",
    "con.commit()\n",
    "\n",
    "cur.close()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('data_wrangling_sqlite.db') #nome do banco de dados\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "with open('ways_tags.csv', 'r', encoding='utf-8') as file:\n",
    "    dr = csv.DictReader(file) # nome do arquivo csv\n",
    "    to_db = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "    # i['nome da coluna']\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags VALUES (?,?,?,?);\", to_db)# ? = número de colunas\n",
    "\n",
    "con.commit()\n",
    "\n",
    "cur.close()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para obtenção de amostra dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"map\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para contagem de tags da amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'osm': 1,\n",
       " 'note': 1,\n",
       " 'meta': 1,\n",
       " 'bounds': 1,\n",
       " 'node': 207207,\n",
       " 'tag': 154792,\n",
       " 'way': 30893,\n",
       " 'nd': 250875,\n",
       " 'relation': 1711,\n",
       " 'member': 20039}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    dict_tags = {}\n",
    "    for el in root.iter():\n",
    "        if el.tag not in dict_tags:\n",
    "            dict_tags[el.tag] = 1\n",
    "        else:\n",
    "            dict_tags[el.tag] += 1\n",
    "    return dict_tags\n",
    "\n",
    "count_tags(r\"C:\\Users\\Eleandro\\Downloads\\map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para identificação de problemas nas tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 105370, 'lower_colon': 47172, 'problemchars': 0, 'other': 2250}\n",
      "\n",
      "['fuel:octane_87',\n",
      " 'fuel:octane_98',\n",
      " 'fuel:octane_87',\n",
      " 'fuel:octane_95',\n",
      " 'fuel:octane_87']\n"
     ]
    }
   ],
   "source": [
    "# O código a seguir tem por fim a identificação da nomes problemáticos utilizados como valor\n",
    "# no par chave:valor das tags.\n",
    "# O resultado retorna um dicionários com a quantidade de valores com caracteres em letras \n",
    "# minúsculas (lower), como carácteres em letras minúsculas com dois pontos (lower_colon),\n",
    "# com caracteres problemáticos (problemchars) e com caracteres que não se encaixam em nenuma\n",
    "# das opções anteriores (other). Para exemplificar a valores classificados como 'other', criou-\n",
    "# se uma lista denominada other_list e foram impressos os cinco primeiros itens da lista.\n",
    " \n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "list_other = []\n",
    "\n",
    "# função para determinar o conteúdo das chaves dos elementos tag do mapa e efetuar a contagem\n",
    "# do número de chaves para cada uma das classificações (lower, lower_colon, problemchars e\n",
    "# other).\n",
    "def key_type(element, keys):    \n",
    "    if element.tag == \"tag\":\n",
    "        target = element.get('k')\n",
    "        if lower.search(target):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(target):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(target):\n",
    "            keys['problemchars'] += 1            \n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "            list_other.append(target)    \n",
    "    return keys              \n",
    "    \n",
    "# função para processar o arquivo do mapa, mediante aplicação da função key_type, acima\n",
    "# descrita.\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)            \n",
    "    return keys\n",
    "\n",
    "chaves = process_map(r\"C:\\Users\\Eleandro\\Downloads\\map\")\n",
    "print(chaves)\n",
    "print('')\n",
    "pprint.pprint(list_other[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para identificação dos tipos da vias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alameda', 'Avenida', 'Beco', 'Praça', 'Rodovia', 'Rua', 'Travessa', 'Via'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = r\"C:\\Users\\Eleandro\\Downloads\\map\"\n",
    "\n",
    "# expressão regular para buscar o denominação da via.\n",
    "street_type_re = re.compile(r'^\\b\\S+\\.?', re.IGNORECASE)\n",
    "\n",
    "# função que verifica a existência do tipo da via e adiciona a um dicionário um única vez o \n",
    "# tipo da via e as respectivas denominações.\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        street_types[street_type].add(street_name)\n",
    "\n",
    "# função que verifica se o elemento chave da tag é própria para identificação de vias.         \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# função que itera o mapa nas tags way e node aplicando as funções acima e retorna, neste caso,\n",
    "# apenas os tipos das vias (ruas, avenidas, etc), que é o objetivo do código. A função cria,\n",
    "# também, um dicionário que contem os tipos das vias com o atributo set.\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\", encoding='utf-8')\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return set(street_types.keys())\n",
    "\n",
    "audit(OSMFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para atualizar e substituir os nomes de via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "\n",
    "OSMFILE = r\"C:\\Users\\Eleandro\\Downloads\\map\"\n",
    "\n",
    "street_type_re = re.compile(r'^\\b\\S+\\.?', re.IGNORECASE)\n",
    "\n",
    "#expected = ['Rodovia', 'Rua', 'Avenida', 'Alameda', 'Travessa', 'Praça', 'Parque', \n",
    "#            'Ponte', 'Via', 'Beco']\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = {\"BR-470\": \"Rodovia BR-470\"}\n",
    "\n",
    "tree = ET.parse(OSMFILE)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def update_name(mapping):                  \n",
    "    osm_file = open(OSMFILE, 'r+', encoding='utf-8')\n",
    "    for elem in tree.iter():\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    m = street_type_re.search(tag.attrib['v'])\n",
    "                    if m:\n",
    "                        street_type = m.group()\n",
    "                        #print(street_type)\n",
    "                        if street_type in mapping.keys():\n",
    "                            new_st_type = mapping[street_type]\n",
    "                            print(new_st_type)\n",
    "                            old_value = tag.attrib['v']\n",
    "                            print(old_value)\n",
    "                            new_value = old_value.replace(street_type, new_st_type)\n",
    "                            if tag.attrib['v']:\n",
    "                                tag.set('v',new_value)\n",
    "                                print(tag.attrib['v'])\n",
    "                            \n",
    "    tree.write(OSMFILE, encoding='utf-8')            \n",
    "    osm_file.close()\n",
    "\n",
    "update_name(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localização das cidades do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Blumenau', 21)\n",
      "('Indaial', 6)\n",
      "('Timbó', 2)\n",
      "('Pomerode', 1)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('''SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "      SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key LIKE 'addr:city'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;''')\n",
    "lista = cursor.fetchall()\n",
    "for l in lista:\n",
    "    print(l)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código de recuperação de usuários do OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('adrianojbr', 86496)\n",
      "('André Alvarenga', 69749)\n",
      "('sirach', 17098)\n",
      "('Victor 2015', 4257)\n",
      "('MeisterLampe', 3625)\n"
     ]
    }
   ],
   "source": [
    "# código que faz conexão do notebook com o arquivo do banco de dados SQLite, atribuindo o\n",
    "# resultado da consulta à variável lista.\n",
    "\n",
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('''SELECT user, COUNT(*) as Quantidade FROM nodes GROUP by user ORDER\n",
    "by quantidade DESC LIMIT 5;''')\n",
    "lista = cursor.fetchall()\n",
    "for l in lista:\n",
    "    print(l)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "# código que faz conexão do notebook com o arquivo do banco de dados SQLite, para consulta\n",
    "#de usuários que contribuiram uma única vez, atribuindo o resultado da consulta à variável \n",
    "#lista.\n",
    "\n",
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "conexao.row_factory = lambda cursor, row: row[0]\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('''SELECT COUNT(DISTINCT(e.uid))          \n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;''')\n",
    "lista = cursor.fetchall()\n",
    "for l in lista:\n",
    "    print(l)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código de recuperação de websites do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bpsconstrutora.com.br',)\n",
      "('http://5asec.com.br/',)\n",
      "('http://abalone.com.br/',)\n",
      "('http://abcescolademusica.com.br/',)\n",
      "('http://achievelanguages.com.br/',)\n"
     ]
    }
   ],
   "source": [
    "# código que faz conexão do notebook com o arquivo do banco de dados SQLite, atribuindo o\n",
    "# resultado da consulta à variável lista.\n",
    "\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('''SELECT tags.value FROM\n",
    "(SELECT * FROM ways_tags UNION SELECT * FROM nodes_tags) tags WHERE tags.key like '%website'\n",
    "GROUP BY tags.value LIMIT 5;''')\n",
    "lista = cursor.fetchall()\n",
    "for l in lista:\n",
    "    print(l)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para verificação dos locais mais comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('telephone', 204)\n",
      "('waste_disposal', 136)\n",
      "('fast_food', 110)\n",
      "('restaurant', 104)\n",
      "('bench', 83)\n",
      "('pharmacy', 78)\n",
      "('waste_basket', 61)\n",
      "('clinic', 59)\n",
      "('cafe', 56)\n",
      "('dentist', 50)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "#conexao.row_factory = lambda cursor, row: row[0]\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute ('''SELECT value, COUNT(*) as num FROM nodes_tags WHERE key='amenity' GROUP\n",
    "BY value ORDER BY num DESC LIMIT 10;''')\n",
    "lista = cursor.fetchall()\n",
    "for l in lista:\n",
    "    print(l)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para investigação de CEPs do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de CEPs: 387\n",
      "Blumenau: 356\n",
      "Pomerode: 0\n",
      "Indaial: 0\n",
      "Gaspar: 1\n",
      "Timbó: 0\n",
      "CEPs estranhos: [89130, 89370, 89000]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "\n",
    "# a aplicação do método row_factory permite a apresentação do resultado da consulta em formato\n",
    "# de lista em vez de tupla.\n",
    "conexao.row_factory = lambda cursor, row: row[0]\n",
    "cursor = conexao.cursor()\n",
    "\n",
    "# Consulta ao banco de dados para obtenção do número total de CEPs existentes na tabela\n",
    "# ways_tags.\n",
    "cursor.execute('''select count(*) as TotaldeCEPs from ways_tags wt where (SELECT wt.value\n",
    "from ways_tags) and wt.key like '%post%';''')\n",
    "total = cursor.fetchone()\n",
    "print('Número total de CEPs: ' + str(total))\n",
    "\n",
    "# Código de consulta ao banco de dados para obtenção do número de CEPs compreendidos entre\n",
    "# os valores determinados, que são relativos a determinado município, conforme exposto acima.\n",
    "cursor.execute('''select count(*) as CEPs from ways_tags wt where (SELECT wt.value from\n",
    "ways_tags where wt.value >= 89001 and wt.value <= 89079) and wt.key like '%post%';''')\n",
    "blu = cursor.fetchone()\n",
    "print('Blumenau: ' + str(blu))\n",
    "\n",
    "cursor.execute('''select count(*) as CEPs from ways_tags wt where (SELECT wt.value from\n",
    "ways_tags where wt.value >= 89107 and wt.value <= 89107) and wt.key like '%post%';''')\n",
    "pom = cursor.fetchone()\n",
    "print('Pomerode: ' + str(pom))\n",
    "\n",
    "cursor.execute('''select count(*) as CEPs from ways_tags wt where (SELECT wt.value from\n",
    "ways_tags where wt.value >= 89080 and wt.value <= 89089) and wt.key like '%post%';''')\n",
    "ind = cursor.fetchone()\n",
    "print('Indaial: ' + str(ind))\n",
    "\n",
    "cursor.execute('''select count(*) as CEPs from ways_tags wt where (SELECT wt.value from\n",
    "ways_tags where wt.value >= 89110 and wt.value <= 89119) and wt.key like '%post%';''')\n",
    "gas = cursor.fetchone()\n",
    "print('Gaspar: ' + str(gas))\n",
    "\n",
    "cursor.execute('''select count(*) as CEPs from ways_tags wt where (SELECT wt.value from\n",
    "ways_tags where wt.value >= 89120 and wt.value <= 89120) and wt.key like '%post%';''')\n",
    "tim = cursor.fetchone()\n",
    "print('Timbó: ' + str(tim))\n",
    "\n",
    "# Retorna lista de todos os CEPs, atribuída a variável n.\n",
    "cursor.execute('''select wt.value as CEPs from ways_tags wt where \n",
    "wt.key like '%post%';''')\n",
    "n = cursor.fetchall()\n",
    "#print((n))\n",
    "\n",
    "# Lista para conter os CEPs encontrados localmente, utilizando-se somente os cinco primeiros\n",
    "# números do CEP, mediante atribuição do CEP à variável it e apensando o valor à lista\n",
    "# cep_local.\n",
    "cep_local = []\n",
    "for item in n:\n",
    "    it = int(item[0:5])\n",
    "    if it not in cep_local:\n",
    "        cep_local.append(it)\n",
    "\n",
    "# Cria a lista ceps na qual serão contidos todos os CEPs (primeiro cinco números) relativos à\n",
    "# faixa de CEP atribuída pelos Correios a cada um dos munícipios abrangidos  pela amostra do\n",
    "# mapa.\n",
    "ceps = []\n",
    "for cep in range(89001,89079):\n",
    "    ceps.append(cep)\n",
    "for cep in range(89107,89108):\n",
    "    ceps.append(cep)\n",
    "for cep in range(89080,89090):\n",
    "    ceps.append(cep)\n",
    "for cep in range(89110,89119):\n",
    "    ceps.append(cep)\n",
    "for cep in range(89120,89121):\n",
    "    ceps.append(cep)\n",
    "\n",
    "# Compara os CEPs em cada uma das listas acima (cep_local e ceps) e apensa os CEPs encontrados\n",
    "# na lista cep_local mas não encontrado na lista ceps na lista cep_diferente, uma vez que o CEP\n",
    "# constante na amostra do mapa não existe ou não corresponde a um CEP da faixa de CEPs atribuí-\n",
    "# da pelos Correios para os municípios.\n",
    "cep_diferente = []\n",
    "for item in cep_local:\n",
    "    for c in ceps:\n",
    "        if item not in ceps:\n",
    "            if item not in cep_diferente:\n",
    "                cep_diferente.append(item)\n",
    "print('CEPs estranhos: ' + str(cep_diferente))           \n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285907761\n"
     ]
    }
   ],
   "source": [
    "# No código abaixo, para fins de identificar se apenas o CEP foi inserido equivocadamente ou\n",
    "# se o endereço de outra localidade que não pertencente a área da amostra foi incluído no \n",
    "# banco de dados do OpenStreetMap, procedeu-se à extração do id do registro.\n",
    "\n",
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "conexao.row_factory = lambda cursor, row: row[0]\n",
    "cursor = conexao.cursor()\n",
    "cursor.execute('''SELECT ways_tags.id from ways_tags where ways_tags.value like '89370%';''')\n",
    "retorna_id = cursor.fetchone()\n",
    "print(retorna_id)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presídio Regional de Blumenau\n"
     ]
    }
   ],
   "source": [
    "# A partir do id do registro da tabela ways_tags obtido, buscou-se descobrir qual a referência\n",
    "# do CEP 89370 no mapa amostral e o resultado foi o Presídio Regional de Blumenau, enquanto o\n",
    "# CEP em questão pertence ao município de Papanduva, no norte do estado de Santa Catarina e que\n",
    "# não limitrofe ao município de Blumenau ou aos outros municípios abrangidos pela amostra, de\n",
    "# acordo com o que já apontavam os dados obtidos.\n",
    "\n",
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "conexao.row_factory = lambda cursor, row: row[0]\n",
    "cursor = conexao.cursor()\n",
    "# Consulta o valor da tabela ways_tags associado à chave name e ao id retornado na consulta\n",
    "# acima para determinar o nome do local atribuído ao CEP equivocado.\n",
    "cursor.execute('''SELECT ways_tags.value from ways_tags \n",
    "where ways_tags.id == '285907761' and ways_tags.key == 'name';''')\n",
    "retorna_id = cursor.fetchone()\n",
    "print(retorna_id)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('addr:housenumber', '4585'), ('addr:postcode', '89370-240'), ('addr:street', 'Rua General Osório'), ('amenity', 'prison'), ('barrier', 'wall'), ('building', 'yes'), ('contact:email', 'presidioblumenau@deap.sc.gov.br'), ('contact:phone', '+55 47 2102-9357;+55 47 2102-9350;+55 47 2102-9360'), ('name', 'Presídio Regional de Blumenau'), ('operator', 'Departamento de Administração Prisional')]\n"
     ]
    }
   ],
   "source": [
    "# Investigando-se o dado acima obtido, verificou-se que o objeto (Presídio Regional) não\n",
    "# deveria ter sido incluído como uma tag de way, pois não se trata propriamente de um caminho,\n",
    "# mas sim de um local específico, o qual, a meu juízo, deveria ter sido classificado com um \n",
    "# node.\n",
    "\n",
    "import sqlite3\n",
    "conexao = sqlite3.connect(\"data_wrangling_sqlite.db\")\n",
    "cursor = conexao.cursor()\n",
    "# consulta aos pares de chave-valores vinculados ao dado id da tabela ways_tags.\n",
    "cursor.execute('''SELECT ways_tags.key, ways_tags.value from ways_tags \n",
    "where ways_tags.id == '285907761';''')\n",
    "retorna_id = cursor.fetchall()\n",
    "print(retorna_id)\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
